{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f64cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "from twilio.rest import Client\n",
    "import datetime\n",
    "\n",
    "class EmotionDetector:\n",
    "    def __init__(self, image_path):\n",
    "        \"\"\"\n",
    "        Initialize the EmotionDetector with the image path.\n",
    "\n",
    "        Args:\n",
    "        - image_path (str): Path to the image file.\n",
    "        \"\"\"\n",
    "        self.image_path = image_path\n",
    "        self.image = cv2.imread(image_path)\n",
    "        if self.image is None:\n",
    "            raise ValueError(f\"Image not found or could not be loaded: {image_path}\")\n",
    "        self.predictions = None\n",
    "\n",
    "    def analyze_emotion(self):\n",
    "        \"\"\"\n",
    "        Analyze the emotion of the image using DeepFace.\n",
    "\n",
    "        Returns:\n",
    "        - str: Dominant emotion detected in the image.\n",
    "        \"\"\"\n",
    "        self.predictions = DeepFace.analyze(self.image)\n",
    "        return self.predictions[0]['dominant_emotion']\n",
    "\n",
    "    def display_emotion(self):\n",
    "        \"\"\"\n",
    "        Display the image with the dominant emotion label.\n",
    "        \"\"\"\n",
    "        dominant_emotion = self.predictions[0]['dominant_emotion']\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(self.image, dominant_emotion, (0, 50), font, 3, (0, 255, 0), 2, cv2.LINE_4)\n",
    "        plt.imshow(cv2.cvtColor(self.image, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "class WeaponDetector:\n",
    "    def __init__(self, gun_cascade_path='gun_cascade.xml', knife_cascade_path='knife_cascade.xml', bat_cascade_path='bat_cascade.xml'):\n",
    "        \"\"\"\n",
    "        Initialize the WeaponDetector with cascade classifiers for guns, knives, and bats.\n",
    "\n",
    "        Args:\n",
    "        - gun_cascade_path (str): Path to the gun cascade classifier XML file.\n",
    "        - knife_cascade_path (str): Path to the knife cascade classifier XML file.\n",
    "        - bat_cascade_path (str): Path to the bat cascade classifier XML file.\n",
    "        \"\"\"\n",
    "        self.gun_cascade = cv2.CascadeClassifier(gun_cascade_path)\n",
    "        self.knife_cascade = cv2.CascadeClassifier(knife_cascade_path)\n",
    "        self.bat_cascade = cv2.CascadeClassifier(bat_cascade_path)\n",
    "        self.camera = cv2.VideoCapture(0)\n",
    "        self.previous_frame = None\n",
    "        self.weapon_detected = False\n",
    "\n",
    "    def detect_weapon(self):\n",
    "        \"\"\"\n",
    "        Detect weapons (guns, knives, bats) using the camera feed.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            ret, current_frame = self.camera.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            current_frame = cv2.resize(current_frame, (500, 375))\n",
    "            gray_frame = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect guns\n",
    "            guns = self.gun_cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=20, minSize=(100, 100))\n",
    "            # Detect knives\n",
    "            knives = self.knife_cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=20, minSize=(100, 100))\n",
    "            # Detect bats\n",
    "            bats = self.bat_cascade.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=20, minSize=(100, 100))\n",
    "\n",
    "            # If any weapons are detected, set weapon_detected to True and draw rectangles around them\n",
    "            if len(guns) > 0 or len(knives) > 0 or len(bats) > 0:\n",
    "                self.weapon_detected = True\n",
    "                for (x, y, w, h) in guns:\n",
    "                    cv2.rectangle(current_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "                for (x, y, w, h) in knives:\n",
    "                    cv2.rectangle(current_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                for (x, y, w, h) in bats:\n",
    "                    cv2.rectangle(current_frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "            # Display current frame with timestamp\n",
    "            if self.previous_frame is None:\n",
    "                self.previous_frame = gray_frame\n",
    "                continue\n",
    "\n",
    "            timestamp = datetime.datetime.now().strftime(\"%A %d %B %Y %I:%M:%S %p\")\n",
    "            cv2.putText(current_frame, timestamp, (10, current_frame.shape[0] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "\n",
    "            # If weapons are detected, display the frame and break out of the loop\n",
    "            if self.weapon_detected:\n",
    "                print(\"Weapons detected\")\n",
    "                cv2.imshow(\"Weapons Detected\", current_frame)\n",
    "                break\n",
    "            else:\n",
    "                cv2.imshow(\"Security Feed\", current_frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        self.camera.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "class AnimalDetector:\n",
    "    def __init__(self):\n",
    "        self.model = InceptionV3(weights='imagenet')\n",
    "\n",
    "    def detect_animal(self, image_path):\n",
    "        \"\"\"\n",
    "        Detect animals (dogs, snakes, spiders, birds, pigs, goats, horses, rats, mice, ferrets, cats) in the image.\n",
    "\n",
    "        Args:\n",
    "        - image_path (str): Path to the image file.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: (status, animals_detected)\n",
    "          - status (str): 'yes' if animals are detected, 'no' otherwise.\n",
    "          - animals_detected (list): List of detected animal labels.\n",
    "        \"\"\"\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Image not found or could not be loaded: {image_path}\")\n",
    "        image = cv2.resize(image, (299, 299))\n",
    "        image = preprocess_input(image)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        predictions = self.model.predict(image)\n",
    "        decoded_predictions = decode_predictions(predictions, top=5)[0]\n",
    "\n",
    "        # Check if any of the top predictions match the specified animal labels\n",
    "        animals_detected = [label for (_, label, _) in decoded_predictions if any(animal in label.lower() for animal in ['dog', 'snake', 'spider', 'bird', 'pig', 'goat', 'horse', 'rat', 'mouse', 'ferret', 'cat'])]\n",
    "        if animals_detected:\n",
    "            print(f\"Animals detected: {', '.join(animals_detected)}\")\n",
    "            return 'yes', animals_detected\n",
    "        else:\n",
    "            print(\"No animals detected.\")\n",
    "            return 'no', []\n",
    "\n",
    "\n",
    "class AlertSystem:\n",
    "    def __init__(self, account_sid, auth_token, to_phone_number, from_phone_number):\n",
    "        \"\"\"\n",
    "        Initialize the AlertSystem with Twilio account credentials and phone numbers.\n",
    "\n",
    "        Args:\n",
    "        - account_sid (str): Twilio account SID.\n",
    "        - auth_token (str): Twilio authentication token.\n",
    "        - to_phone_number (str): Phone number to receive alerts.\n",
    "        - from_phone_number (str): Twilio phone number to send alerts from.\n",
    "        \"\"\"\n",
    "        self.client = Client(account_sid, auth_token)\n",
    "        self.to_phone_number = to_phone_number\n",
    "        self.from_phone_number = from_phone_number\n",
    "\n",
    "    def send_alert(self, message_body):\n",
    "        \"\"\"\n",
    "        Send an SMS alert using Twilio.\n",
    "\n",
    "        Args:\n",
    "        - message_body (str): Body of the SMS alert message.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            message = self.client.messages.create(\n",
    "                body=message_body,\n",
    "                from_=self.from_phone_number,\n",
    "                to=self.to_phone_number\n",
    "            )\n",
    "            print(f'SMS sent with SID: {message.sid}')\n",
    "        except Exception as e:\n",
    "            print(f'Error sending SMS: {str(e)}')\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Initialize Emotion Detector with an image file\n",
    "    emotion_detector = EmotionDetector('happy.jpg')\n",
    "    dominant_emotion = emotion_detector.analyze_emotion()  # Analyze the emotion in the image\n",
    "    emotion_detector.display_emotion()  # Display the image with the dominant emotion\n",
    "\n",
    "    # If the detected emotion is 'fear', initialize Weapon Detector\n",
    "    if dominant_emotion == 'fear':\n",
    "        weapon_detector = WeaponDetector()\n",
    "        weapon_detector.detect_weapon()  # Detect weapons\n",
    "\n",
    "        # Determine the alert message based on weapon detection\n",
    "        alert_message = 'weapon detected' if weapon_detector.weapon_detected else 'no weapon detected'\n",
    "\n",
    "        # If no weapon is detected, proceed to detect animals\n",
    "        if alert_message == 'no weapon detected':\n",
    "            animal_detector = AnimalDetector()\n",
    "            animal_status, animals_detected = animal_detector.detect_animal('your_image.jpg')  # Detect animals\n",
    "\n",
    "            # Initialize Alert System with Twilio credentials\n",
    "            alert_system = AlertSystem(\n",
    "                account_sid='AC62b21d18b8e542e7c2ee9b562590bb8f',\n",
    "                auth_token='da3c619b4e15772f50691bdf8c8c5209',\n",
    "                to_phone_number='+447733658594',\n",
    "                from_phone_number='+447480542813'\n",
    "            )\n",
    "            # Send alert with status and detected animals information\n",
    "            alert_system.send_alert('Danger, please help! Animals detected status: ' + animal_status + ', Detected Animals: ' + ', '.join(animals_detected))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
